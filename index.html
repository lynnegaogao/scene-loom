<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="SceneLoom: Communicating Data with Scene Contex.">
  <meta name="keywords" content="Paper, website">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SceneLoom: Communicating Data with Scene Context</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>




  <section class="hero">
    <div class="body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <span class="publication-title">
              <span style="display: inline-flex; align-items: center; gap: 8px;">
                <img src="./static/images/logo.png" alt="SceneLoom Logo" style="height: 1.9em; vertical-align: middle;">
                Communicating Data with Scene Context
              </span>
            </span>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://lynnegao.me/">Lin Gao</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://shenleixian.github.io/">Leixian Shen</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://zyh1222.github.io/">Yuheng Zhao</a><sup>1</sup>,
                <span class="author-block">
                  <a>Jiexiang Lan</a><sup>1</sup>,
                  <span class="author-block">
                    <a href="http://huamin.org/">Huamin Qu</a><sup>2</sup>,
                    <span class="author-block">
                      <a href="http://simingchen.me/">Siming Chen</a><sup>1</sup>,
            </div>

            <div class="publication-authors">
              <span class="author-affiliation-block"><sup>1</sup>Fudan University, Shanghai, China</span><br>
              <span class="author-affiliation-block"><sup>2</sup>The Hong Kong University of Science and Technology,
                Hong Kong SAR, China </span>
            </div>

            <!--<div class="column has-text-centered">-->
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://lynnegao.me/papers/2025-SceneLoom-VIS.pdf">
                  <span>
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.16466">
                  <span>
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="./static/files/Appendix.pdf" target="_blank">
                  <span><i class="fas fa-file-alt"></i></span>
                  <span>Appendix</span>
                </a>
              </span>

              <!-- Video Link. -->
              <!--<span class="link-block">
                <a href="https://drive.google.com/file/d/19eXsSnTAeD-RtIiDqfpjh1bb6WyHYd8R/view">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <!--<span class="link-block">
                <a href="https://github.com/TUM-AVS/paper-website-project"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>-->
              <!-- Dataset Link. -->
              <!--<span class="link-block">
                <a href="https://github.com/TUM-AVS/paper-website-project"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>-->
              <!--</div>-->

              <!--</div>-->
            </div>
          </div>
        </div>
      </div>
  </section>

  <section style="padding: 20px 5px;">
    <div class="container is-max-desktop is-four-fifths">
      <!--<div class="body">-->
      <!--<img src="./static/images/teaser.jpg"
                 class="teaser-image"
                />-->
      <!-- You can also add a video as a teaser -->

      <video autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>



      <!--</div>-->
    </div>
  </section>



  <section>
    <div class="container is-max-desktop" >
      <!-- Abstract. -->
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <span class="section-title">Abstract</span>
          <div class="section-content">
            <p>
              In data-driven storytelling contexts such as data journalism and data videos, data visualizations are
              often presented alongside real-world imagery to support narrative context. However, these visualizations
              and contextual images typically remain separated, limiting their combined narrative expressiveness and
              engagement. Achieving this is challenging due to the need for fine-grained alignment and creative
              ideation. To address this, we present <span class="highlight-brush">SceneLoom</span>,
              a Vision-Language Model (VLM)-powered system that facilitates the coordination of data visualization with
              real-world imagery based on narrative intents.
              Through a formative study, we investigated the design space of coordination relationships between data
              visualization and real-world scenes from the perspectives of visual alignment and semantic coherence.
              Guided by the derived design considerations, SceneLoom leverages VLMs to extract visual and semantic
              features from scene images and data visualization, and perform design mapping through a reasoning process
              that incorporates spatial organization, shape similarity, layout consistency, and semantic binding.
              The system generates a set of contextually expressive, image-driven design alternatives that achieve
              coherent alignments across visual, semantic, and data dimensions.
              Users can explore these alternatives, select preferred mappings, and further refine the design through
              interactive adjustments and animated transitions to support expressive data communication.
              A user study and an example gallery validate SceneLoom's effectiveness in inspiring creative design and
              facilitating design externalization.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered">
        <div class="column is-four-fifths" style="margin-bottom: 20px;">
          <span class="section-title">Introduction Video</span>
          <video id="teaser" controls muted height="100%" >
            <source src="./static/videos/IntroductionVideo.mp4" type="video/mp4">
          </video>

        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>


  <section>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <span class="section-title">Formative Study</span>
          <div class="section-content">
            <p style="margin-bottom: 10px;">
              <span class="highlight-brush">How to coordinate design components from data visualization and real-world imagery in a narrative-driven</span> <span class="highlight-brush">context?</span>
              To derive actionable insights into coordination strategies, we conducted a corpus analysis of existing data videos. 
              Specifically, we examined 54 data videos that integrated both data visualizations and real-world elements. 
              The full set of cases and coding results is available in the following online table. 
              This analysis enabled us to identify common interaction patterns and define a set of analytical dimensions to guide design.
            </p>
            <iframe class="airtable-embed" src="https://airtable.com/embed/apparxcuOrUlTeKj3/shrFcnYr0QytfWLeE" frameborder="0" onmousewheel="" width="100%" height="533" style="background: transparent; border: 1px solid #ccc;"></iframe>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <span class="section-title">Example Gallery</span>
          <div class="section-content">
            <p>
              Here are some representative examples of SceneLoom's generated designs.
            </p>
          </div>
          <div class="columns is-multiline">
            <!-- 第1行 -->
            <div class="column is-half">
              <video controls width="100%">
                <source src="./static/videos/video1.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <div class="column is-half">
              <video controls width="100%">
                <source src="./static/videos/video2.mp4" type="video/mp4">
              </video>
            </div>

            <!-- 第2行 -->
            <div class="column is-half">
              <video controls width="100%">
                <source src="./static/videos/video3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <video controls width="100%">
                <source src="./static/videos/video4.mp4" type="video/mp4">
              </video>
            </div>

            <!-- 第3行 -->
            <div class="column is-half">
              <video controls width="100%">
                <source src="./static/videos/video5.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <video controls width="100%">
                <source src="./static/videos/video6.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

      </div>
    </div>
  </section>





  <section class="section">
    <div class="container is-max-desktop">
      <span class="bibtex-title">BibTeX</span>
      <pre><code>@misc{gao2025sceneloomcommunicatingdatascene,
      title={SceneLoom: Communicating Data with Scene Context}, 
      author={Lin Gao and Leixian Shen and Yuheng Zhao and Jiexiang Lan and Huamin Qu and Siming Chen},
      year={2025},
      eprint={2507.16466},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2507.16466}, 
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="columns is-centered">
      <div class="footer-content">
        <center>
          <p>
            This website (<a href="https://github.com/paper-website/paper-website.github.io">source code</a>) was
            adapted from the popular <a href="https://nerfies.github.io">Nerfies</a> project page and is licensed
            under a <br><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </center>
      </div>
    </div>
  </footer>

</body>

</html>